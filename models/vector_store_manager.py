# models/vector_store_manager.py (ÏÉà ÌååÏùº!)
import os
import pickle
import logging
from typing import Dict, Optional, List
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document

logger = logging.getLogger(__name__)

class VectorStoreManager:
    """Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥ Í¥ÄÎ¶¨ ÌÅ¥ÎûòÏä§ - Ï†ÄÏû•/Î°úÎìú/Ï∫êÏã± Îã¥Îãπ"""
    
    def __init__(self, config):
        self.config = config
        self.embeddings = HuggingFaceEmbeddings(
            model_name=config.EMBEDDING_MODEL,
            model_kwargs={'device': 'cpu'}
        )
        
        # ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±
        os.makedirs(config.VECTOR_DB_PATH, exist_ok=True)
        
        logger.info(f"üìÅ Vector store manager initialized")
        logger.info(f"   Storage path: {config.VECTOR_DB_PATH}")
    
    def load_or_create_assay_vectorstore(self, train_data: List[Dict]) -> Optional[FAISS]:
        """Assay Î≤°ÌÑ∞Ïä§ÌÜ†Ïñ¥ Î°úÎìú ÎòêÎäî ÏÉùÏÑ±"""
        
        # 1. Í∏∞Ï°¥ Î≤°ÌÑ∞Ïä§ÌÜ†Ïñ¥ Î°úÎìú ÏãúÎèÑ
        if not self.config.FORCE_REBUILD_VECTORSTORE and os.path.exists(self.config.ASSAY_VECTORSTORE_PATH):
            try:
                logger.info("üìÇ Loading existing assay vectorstore...")
                vectorstore = FAISS.load_local(
                    self.config.ASSAY_VECTORSTORE_PATH, 
                    self.embeddings,
                    allow_dangerous_deserialization=True
                )
                logger.info(f"‚úÖ Loaded existing vectorstore with {vectorstore.index.ntotal} vectors")
                return vectorstore
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Failed to load existing vectorstore: {e}")
                logger.info("üîÑ Will create new vectorstore instead...")
        
        # 2. ÏÉà Î≤°ÌÑ∞Ïä§ÌÜ†Ïñ¥ ÏÉùÏÑ±
        logger.info("üèóÔ∏è Creating new assay vectorstore...")
        vectorstore = self._create_assay_vectorstore(train_data)
        
        # 3. Ï†ÄÏû•
        if vectorstore and self.config.SAVE_VECTORSTORE:
            try:
                logger.info("üíæ Saving vectorstore for future use...")
                vectorstore.save_local(self.config.ASSAY_VECTORSTORE_PATH)
                logger.info(f"‚úÖ Vectorstore saved to {self.config.ASSAY_VECTORSTORE_PATH}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Failed to save vectorstore: {e}")
        
        return vectorstore
    
    def _create_assay_vectorstore(self, train_data: List[Dict]) -> Optional[FAISS]:
        """ÏÉàÎ°úÏö¥ Assay Î≤°ÌÑ∞Ïä§ÌÜ†Ïñ¥ ÏÉùÏÑ±"""
        from .data_parser import DataParser
        
        assay_documents = []
        
        for idx, item in enumerate(train_data):
            parsed = DataParser.parse_input_text(item['input_text'])
            logac50 = int(item['output_text'])
            
            if parsed['assay_description']:
                activity_category = self._categorize_activity(logac50)
                
                assay_doc_content = f"""
                Assay: {parsed['assay_name']}
                Description: {parsed['assay_description']}
                Activity: {logac50}
                Category: {activity_category}
                Instructions: {parsed['instruction']}
                """
                
                assay_doc = Document(
                    page_content=assay_doc_content,
                    metadata={
                        'assay_name': parsed['assay_name'],
                        'logac50': logac50,
                        'idx': idx,
                        'activity_category': activity_category
                    }
                )
                assay_documents.append(assay_doc)
            
            if (idx + 1) % 100 == 0:
                logger.info(f"   Processed {idx + 1}/{len(train_data)} documents...")
        
        if not assay_documents:
            logger.warning("‚ö†Ô∏è No assay documents found for vectorstore creation")
            return None
        
        # Î¨∏ÏÑú Î∂ÑÌï†
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.config.CHUNK_SIZE,
            chunk_overlap=self.config.CHUNK_OVERLAP
        )
        split_docs = text_splitter.split_documents(assay_documents)
        
        # FAISS Î≤°ÌÑ∞Ïä§ÌÜ†Ïñ¥ ÏÉùÏÑ±
        vectorstore = FAISS.from_documents(split_docs, self.embeddings)
        
        logger.info(f"‚úÖ Created vectorstore with {len(split_docs)} chunks from {len(assay_documents)} documents")
        
        return vectorstore
    
    def load_or_create_fingerprint_cache(self, parsed_train_data: List[Dict]) -> Dict:
        """Î∂ÑÏûê ÏßÄÎ¨∏ Ï∫êÏãú Î°úÎìú ÎòêÎäî ÏÉùÏÑ±"""
        
        # 1. Í∏∞Ï°¥ Ï∫êÏãú Î°úÎìú ÏãúÎèÑ
        if not self.config.FORCE_REBUILD_VECTORSTORE and os.path.exists(self.config.FINGERPRINT_CACHE_PATH):
            try:
                logger.info("üìÇ Loading existing fingerprint cache...")
                with open(self.config.FINGERPRINT_CACHE_PATH, 'rb') as f:
                    cache = pickle.load(f)
                logger.info(f"‚úÖ Loaded fingerprint cache with {len(cache)} entries")
                return cache
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Failed to load fingerprint cache: {e}")
                logger.info("üîÑ Will create new cache instead...")
        
        # 2. ÏÉà Ï∫êÏãú ÏÉùÏÑ±
        logger.info("üèóÔ∏è Creating new fingerprint cache...")
        cache = self._create_fingerprint_cache(parsed_train_data)
        
        # 3. Ï†ÄÏû•
        if self.config.SAVE_VECTORSTORE:
            try:
                logger.info("üíæ Saving fingerprint cache for future use...")
                with open(self.config.FINGERPRINT_CACHE_PATH, 'wb') as f:
                    pickle.dump(cache, f)
                logger.info(f"‚úÖ Fingerprint cache saved to {self.config.FINGERPRINT_CACHE_PATH}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Failed to save fingerprint cache: {e}")
        
        return cache
    
    def _create_fingerprint_cache(self, parsed_train_data: List[Dict]) -> Dict:
        """ÏÉàÎ°úÏö¥ Î∂ÑÏûê ÏßÄÎ¨∏ Ï∫êÏãú ÏÉùÏÑ±"""
        from .utils import create_mol_object, generate_fingerprints
        
        cache = {}
        processed = 0
        
        for example in parsed_train_data:
            if 'fingerprints' in example and example['fingerprints']:
                # Ïù¥ÎØ∏ Ï≤òÎ¶¨Îêú Í≤ΩÏö∞
                cache[example['smiles']] = example['fingerprints']
                processed += 1
            elif example['smiles']:
                # ÏÉàÎ°ú Ï≤òÎ¶¨
                mol = create_mol_object(example['smiles'])
                if mol is not None:
                    fingerprints = generate_fingerprints(mol, example['smiles'])
                    if fingerprints:
                        cache[example['smiles']] = fingerprints
                        processed += 1
            
            if processed % 100 == 0:
                logger.info(f"   Processed {processed} fingerprints...")
        
        logger.info(f"‚úÖ Created fingerprint cache with {len(cache)} entries")
        return cache
    
    def _categorize_activity(self, logac50: int) -> str:
        """ÌôúÏÑ±ÎèÑ Ïπ¥ÌÖåÍ≥†Î¶¨ Î∂ÑÎ•ò"""
        if logac50 >= 85:
            return "Very High"
        elif logac50 >= 70:
            return "High"
        elif logac50 >= 50:
            return "Medium"
        elif logac50 >= 30:
            return "Low"
        else:
            return "Very Low"
    
    def get_vectorstore_info(self) -> Dict:
        """Î≤°ÌÑ∞Ïä§ÌÜ†Ïñ¥ Ï†ïÎ≥¥ Î∞òÌôò"""
        info = {
            'assay_vectorstore_exists': os.path.exists(self.config.ASSAY_VECTORSTORE_PATH),
            'fingerprint_cache_exists': os.path.exists(self.config.FINGERPRINT_CACHE_PATH),
            'vectorstore_path': self.config.ASSAY_VECTORSTORE_PATH,
            'cache_path': self.config.FINGERPRINT_CACHE_PATH
        }
        
        # ÌååÏùº ÌÅ¨Í∏∞ Ï†ïÎ≥¥
        if info['assay_vectorstore_exists']:
            try:
                size = sum(os.path.getsize(os.path.join(self.config.ASSAY_VECTORSTORE_PATH, f)) 
                          for f in os.listdir(self.config.ASSAY_VECTORSTORE_PATH))
                info['vectorstore_size_mb'] = size / (1024 * 1024)
            except:
                info['vectorstore_size_mb'] = 0
        
        if info['fingerprint_cache_exists']:
            try:
                info['cache_size_mb'] = os.path.getsize(self.config.FINGERPRINT_CACHE_PATH) / (1024 * 1024)
            except:
                info['cache_size_mb'] = 0
        
        return info
    
    def clear_all_stores(self):
        """Î™®Îì† Ï†ÄÏû•Îêú Î≤°ÌÑ∞Ïä§ÌÜ†Ïñ¥ÏôÄ Ï∫êÏãú ÏÇ≠Ï†ú"""
        import shutil
        
        try:
            if os.path.exists(self.config.ASSAY_VECTORSTORE_PATH):
                shutil.rmtree(self.config.ASSAY_VECTORSTORE_PATH)
                logger.info("üóëÔ∏è Deleted assay vectorstore")
            
            if os.path.exists(self.config.FINGERPRINT_CACHE_PATH):
                os.remove(self.config.FINGERPRINT_CACHE_PATH)
                logger.info("üóëÔ∏è Deleted fingerprint cache")
                
            logger.info("‚úÖ All vector stores cleared")
        except Exception as e:
            logger.error(f"‚ùå Error clearing stores: {e}")